\documentclass[a4paper, 11pt]{article}

% --- PACHETTI ESSENZIALI ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern} % Font per T1
\usepackage[italian]{babel}
\usepackage{geometry}
\geometry{a4paper, margin=1in}

% --- PACCHETTI MATEMATICI ---
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

% --- PACCHETTI PER GRAFICA E COLORI ---
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows, intersections, calc}
\usepackage[most]{tcolorbox}
\usepackage{graphicx} % Per includere immagini
% --- DEFINIZIONE DEGLI AMBIENTI PERSONALIZZATI ---

% Stile per i riquadri delle formule importanti (simili a quelli rossi/verdi)
\newtcolorbox{formulabox}[1][]{
  colback=blue!5!white,
  colframe=blue!75!black,
  fonttitle=\bfseries,
  colbacktitle=blue!85!black,
  attach boxed title to top center={yshift=-2mm},
  title=#1,
  #1
}

% Teoremi, definizioni, etc.
\theoremstyle{definition}
\newtheorem{definizione}{Definizione}[section]
\newtheorem{regola}{Regola}[section]
\newtheorem{esempio}{Esempio}[section]

% --- INFORMAZIONI SUL DOCUMENTO ---
\date{} % Nessuna data

\begin{document}

\begin{titlepage}
    \centering % Centra tutto il contenuto orizzontalmente

    % Aggiunge uno spazio verticale dall'alto per abbassare il titolo
    \vspace*{5cm}

    % Titolo del documento
    \Huge
    \textbf{Appunti di probabilità}

    \vfill % Questo comando spinge il contenuto successivo in fondo alla pagina

    % Autore allineato a destra
    \begin{flushright}
        \Large % Rende il nome dell'autore leggermente più grande
        Angelo Vaccaro
    \end{flushright}

    % Aggiunge un piccolo margine dal fondo della pagina
    \vspace{1cm}
\end{titlepage}

\tableofcontents
\newpage

\section{Teoria della Probabilità di Base}

Un \textbf{esperimento aleatorio} è un qualsiasi processo che ha più di un possibile risultato e di cui non possiamo prevedere l'esito con certezza.
Chiamiamo \textbf{S} lo \textbf{spazio campionario}, e è l'insieme di tutti i possibili esiti. I \textbf{sottoinsiemi} di S sono detti \textbf{eventi}; un evento è un insieme di uno o più esiti che ci interessano.

\subsection*{Operazioni tra Eventi}

\subsubsection*{Intersezione ($A \cap B$)}
"avviene A" e "avviene B"
\begin{center}
\begin{tikzpicture}
    \draw[name path=A] (0,0) circle (1.2);
    \draw[name path=B] (2,0) circle (1.2);
    \node at (-1.5,1.5) {A};
    \node at (3.5,1.5) {B};

    \begin{scope}
        \clip (0,0) circle (1.2);
        \fill[red!50, opacity=0.7] (2,0) circle (1.2);
    \end{scope}
\end{tikzpicture}
\end{center}
\[ A \cap B = \{s \in S \mid s \in A \text{ e } s \in B\} \]

\subsubsection*{Unione ($A \cup B$)}
"avviene A" o "avviene B" $\rightarrow$ evento in cui si verifica A o B o entrambi.
\begin{center}
\begin{tikzpicture}
    \fill[red!50, opacity=0.7] (0,0) circle (1.2);
    \fill[red!50, opacity=0.7] (2,0) circle (1.2);
    \draw (0,0) circle (1.2);
    \draw (2,0) circle (1.2);
    \node at (-1.5,1.5) {A};
    \node at (3.5,1.5) {B};
\end{tikzpicture}
\end{center}
\[ A \cup B = \{s \in S \mid s \in A \text{ o } s \in B\} \]

\subsubsection*{Differenza ($A \setminus B$)}
"avviene A" ma non "avviene B"
\begin{center}
\begin{tikzpicture}
    % Fill A, then "erase" the part of B by filling it with white
    \fill[red!50, opacity=0.7] (0,0) circle (1.2);
    \fill[white] (2,0) circle (1.2);
    % Redraw the circles
    \draw (0,0) circle (1.2);
    \draw (2,0) circle (1.2);
    \node at (-1.5,1.5) {A};
    \node at (3.5,1.5) {B};
\end{tikzpicture}
\end{center}
\[ A \setminus B = \{s \in S \mid s \in A, s \notin B\} \]

\subsubsection*{Complementare ($A^c$)}
"non avviene A"

\begin{tcolorbox}[colback=green!5!white, colframe=green!60!black, title=Eventi disgiunti o incompatibili]
Due eventi sono disgiunti se non possono accadere contemporaneamente. La loro intersezione è l'insieme vuoto, non ci sono quindi esiti in comune.
\begin{itemize}
    \item \textit{Esempio:} "esce un numero pari" e "esce il 3" sono eventi disgiunti.
\end{itemize}
\end{tcolorbox}

\subsection{Calcolo delle probabilità}
La probabilità, $P(A)$, è un numero che quantifica la "fiducia" che abbiamo nel verificarsi dell'evento A.
\begin{itemize}
    \item $P(A) = 1 \rightarrow$ evento A certo (evento sicuro)
    \item $P(A) = 0 \rightarrow$ evento A impossibile (evento impossibile)
\end{itemize}
\begin{formulabox}
    $0 \le P(A) \le 1 \rightarrow$ tutti gli altri eventi.
\end{formulabox}

La teoria assegna probabilità agli \textbf{insiemi} (eventi), non ai singoli elementi. Nel caso di esiti equiprobabili si arriva alla probabilità del singolo esito, ma il framework è definito sugli eventi.

Non possiamo assegnare valori numeri a caso, dobbiamo rispettare delle regole:

\begin{regola}[Assiomi di Kolmogorov]
\
\begin{enumerate}
    \item \textbf{P(S) = 1} \\
    La probabilità che si verifichi uno qualsiasi dei possibili risultati è 1 (cioè, è una certezza). Lo spazio campionario contiene tutti gli esiti possibili.
    \item \textbf{P(\(\emptyset\)) = 0} \\
    La probabilità dell'evento impossibile è 0.
    \item \textbf{Se A \(\subseteq\) B, allora $P(B) \ge P(A)$} \\
    Se il verificarsi di A implica il verificarsi di B (tutti gli esiti di A sono anche esiti di B), allora la probabilità di B è maggiore o uguale a quella di A. In pratica se si verifica A, necessariamente si verifica B.

    Da questo assioma derivano altre proprietà importanti:
    \begin{itemize}
        \item \textbf{Probabilità del complementare:}
        \begin{formulabox}
            $P(A^c) = 1 - P(A)$
        \end{formulabox}
        La probabilità che un evento non accada è 1 meno la probabilità che accada. Questa formula ci facilita alcuni calcoli.
    \end{itemize}
\end{enumerate}
\end{regola}

\newpage

\subsection{Regole di Calcolo Fondamentali}

\subsubsection{Additività per eventi disgiunti}
Se 2 eventi non possono accadere insieme (disgiunti), la probabilità che accada o l'uno o l'altro è semplicemente la somma delle probabilità individuali.
\begin{formulabox}
    Se $A_i \cap A_j = \emptyset$ per ogni $i \neq j$, allora:
    \[ P\left(\bigcup_{i=1}^{n} A_i\right) = \sum_{i=1}^{n} P(A_i) \]
\end{formulabox}
\textit{Nota: questo vale solo se gli eventi sono a due a due disgiunti.}

\subsubsection{Regola generale per l'unione}
Per due eventi qualsiasi, non necessariamente disgiunti:
\begin{formulabox}
    $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
\end{formulabox}
\textit{Togliamo dalla somma la parte ripetuta.}

\subsection{Probabilità ad Esiti Equiprobabili}
\begin{definizione}
Questa è la formula "classica". Funziona solo se tutti gli esiti dello spazio campionario S hanno la stessa identica probabilità di avvenire.
\begin{formulabox}
    $P(A) = \frac{|A|}{|S|} = \frac{\text{numero di esiti favorevoli}}{\text{numero di esiti possibili}}$
\end{formulabox}
\begin{itemize}
    \item $|A| \rightarrow$ \textbf{cardinalità di A}, n° di esiti che compongono l'evento A.
    \item $|S| \rightarrow$ \textbf{cardinalità di S}, il n° totale di esiti possibili.
\end{itemize}
\end{definizione}

\subsection{Strumenti di Calcolo Combinatorio}

\subsubsection{Coefficiente binomiale}
Questa formula conta in quanti modi si possono scegliere $k$ oggetti da un insieme di $n$ elementi, \textbf{senza} considerare l'ordine e \textbf{senza} reinserimento.
\begin{formulabox}
    $\binom{n}{k} = \frac{n!}{k!(n-k)!}$
\end{formulabox}
\begin{esempio}
Devo scegliere 6 carte da un mazzo di 52:
\[ \binom{52}{6} = \frac{52 \cdot 51 \cdot 50 \cdot 49 \cdot 48 \cdot 47}{6 \cdot 5 \cdot 4 \cdot 3 \cdot 2 \cdot 1} = 20,358,520 \]
\end{esempio}

\subsubsection{Disposizioni semplici (senza reinserimento)}
Questa formula si utilizza invece quando l'\textbf{ordine conta}.
\begin{formulabox}
    $D(n,k) = \frac{n!}{(n-k)!}$
\end{formulabox}
\begin{esempio}
In quanti modi diversi si possono assegnare le 3 posizioni sul podio? (8 atleti)
\[ D(8,3) = \frac{8!}{(8-3)!} = \frac{8!}{5!} = 8 \cdot 7 \cdot 6 = 336 \]
\end{esempio}

\subsubsection{Disposizioni con ripetizione}
Questa è la situazione in cui estrai $k$ oggetti da un insieme di $n$, l'ordine conta, e puoi estrarre lo stesso oggetto più volte.
\begin{formulabox}
    $D'(n,k) = n^k$
\end{formulabox}
\begin{esempio}
Stiamo scegliendo $k=3$ cifre da un insieme di $n=10$ cifre disponibili. L'ordine conta e le cifre si possono ripetere.
\[ D'(10,3) = 10^3 = 1000 \]
\end{esempio}

\newpage

\section{Probabilità Condizionata e Teoremi Collegati}

\subsection{Probabilità condizionata}
La probabilità condizionata è la probabilità che un evento accada sapendo che un altro evento è già avvenuto.
\begin{itemize}
    \item \textbf{Notazione:} $P(A|B) \rightarrow$ "probabilità di A dato B" o "probabilità di A sapendo che B"
\end{itemize}

\begin{formulabox}[title={Definizione di Probabilità Condizionata}]
    \[ P(A|B) = \frac{P(A \cap B)}{P(B)}, \quad \text{con } P(B) > 0 \]
\end{formulabox}

$P(A|B)$ non è un nuovo tipo di evento, ma è un nuovo modo di misurare la probabilità di A.

\subsubsection*{Intuizione geometrica}
\begin{center}
\begin{tikzpicture}
    % Disegna i cerchi e le etichette
    \draw[name path=A] (0,0) circle (1.5);
    \draw[name path=B] (2.5,0) circle (1.5);
    \node at (-1.8,1.8) {A};
    \node at (4.3,1.8) {B};

    % Colora l'insieme B (il nuovo spazio campionario)
    \fill[green!20] (2.5,0) circle (1.5);

    % Colora l'intersezione (l'evento favorevole nel nuovo spazio)
    \begin{scope}
        \clip (0,0) circle (1.5);
        \fill[blue!40] (2.5,0) circle (1.5);
    \end{scope}

    % Ridisegna i bordi per pulizia
    \draw (0,0) circle (1.5);
    \draw (2.5,0) circle (1.5);
    \node at (1.25, 0) {$A \cap B$};
\end{tikzpicture}
\end{center}
\begin{itemize}
    \item Quando sappiamo che B è avvenuto, il nostro spazio campionario non è più S, ma si riduce a B.
    \item Dato che siamo confinati dentro B, l'unico modo perché si verifichi anche A è che l'esito cada nella parte di A che si sovrappone a B, ovvero $A \cap B$.
    \item La probabilità condizionata $P(A|B)$ è quindi il "peso" dell'area $A \cap B$ rispetto alla nuova area totale 'B'. Ecco perché la formula divide per $P(B)$.
\end{itemize}

\subsection{Formula delle Probabilità Totali}
Possiamo manipolare la probabilità condizionata per ottenere 2 strumenti potentissimi.

\begin{regola}[Regola delle catene (o formula inversa)]
    È semplicemente un riarrangiamento della formula iniziale. Serve perché a volte è più facile calcolare $P(A|B)$ e $P(B)$.
    \begin{formulabox}
        $P(A \cap B) = P(A|B)P(B)$
    \end{formulabox}
\end{regola}

\begin{regola}[Formula delle probabilità totali]
\begin{center}
\begin{tikzpicture}
    % A intersecato B^c (parte sinistra di A)
    \begin{scope}[even odd rule]
        \clip (0,0) circle (1.5) (2.5,0) circle (1.5);
        \fill[red!50] (0,0) circle (1.5);
    \end{scope}
    % A intersecato B (intersezione)
    \begin{scope}
        \clip (0,0) circle (1.5);
        \fill[blue!50] (2.5,0) circle (1.5);
    \end{scope}
    % Disegna i bordi
    \draw (0,0) circle (1.5) node[above left] {A};
    \draw (2.5,0) circle (1.5) node[above right] {B};
    \node at (1.25,0) {$A \cap B$};
    \node at (-0.8,0) {$A \cap B^c$};
\end{tikzpicture}
\end{center}
Un evento A può essere partizionato dall'evento B e dal suo complementare $B^c$:
\[ A = (A \cap B) \cup (A \cap B^c) \]
Poiché le due parti sono disgiunte, la loro probabilità è la somma delle probabilità:
\[ P(A) = P(A \cap B) + P(A \cap B^c) \]
Ora, usando la formula moltiplicativa su entrambi i termini, otteniamo la formula delle probabilità totali:
\begin{formulabox}
    $P(A) = P(A|B)P(B) + P(A|B^c)P(B^c)$
\end{formulabox}
Questa formula ci permette di calcolare la probabilità totale di un evento A "assemblandolo" pezzo per pezzo, considerando tutti i diversi scenari in cui A potrebbe verificarsi. In questo caso, i due scenari sono "il mondo in cui B accade" e "il mondo in cui B non accade ($B^c$)".
\end{regola}

\subsubsection*{Generalizzazione (Concetto di Partizione)}
Invece di dividere il mondo solo in "B accade" e "B non accade", possiamo dividerlo in n scenari $B_1, B_2, \dots, B_n$. Una \textbf{partizione} è un insieme di eventi che sono:
\begin{enumerate}
    \item \textbf{Mutuamente esclusivi:} $B_i \cap B_j = \emptyset$ (non hanno elementi in comune per $i \neq j$)
    \item \textbf{Esaustivi:} $\bigcup_i B_i = S$ (la loro unione copre tutte le possibilità)
\end{enumerate}

\subsubsection*{Formula Generale delle Probabilità Totali}
Se $\{B_1, B_2, \dots, B_n\}$ è una partizione, allora la probabilità di un qualsiasi evento A è:
\begin{formulabox}
    $P(A) = P(A|B_1)P(B_1) + P(A|B_2)P(B_2) + \dots + P(A|B_n)P(B_n)$
    \[ P(A) = \sum_{i=1}^{n} P(A|B_i)P(B_i) \]
\end{formulabox}
\textit{Stiamo facendo ancora la stessa cosa: calcoliamo la probabilità di A in ogni possibile "mondo" $B_i$ e poi facciamo una media pesata di queste probabilità.}

\subsection{Teorema di Bayes}
La formula delle probabilità totali ci permette di passare dalle \textbf{cause} (gli scenari, $B_i$) agli \textbf{effetti} (l'osservazione, A). Il teorema di Bayes fa il percorso inverso: osserviamo un effetto (A) e vogliamo calcolare la probabilità di una specifica \textbf{causa} ($B_i$).

Partiamo da 2 modi di scrivere $P(A \cap B)$:
\begin{enumerate}
    \item $P(A \cap B) = P(A|B)P(B)$ \quad [definizione di $P(A|B)$]
    \item $P(B \cap A) = P(B|A)P(A)$ \quad [definizione di $P(B|A)$]
\end{enumerate}
Poiché l'intersezione è commutativa ($A \cap B = B \cap A$), quindi i termini a destra devono essere uguali. Ora, isolando il termine $P(B|A)$ (la probabilità della causa dato l'effetto), otteniamo la formula:
\begin{formulabox}[title={Teorema di Bayes (forma semplice)}]
    \[ P(B|A) = \frac{P(A|B)P(B)}{P(A)} \]
\end{formulabox}

\subsubsection*{Estensione del Teorema di Bayes (n eventi)}
\begin{itemize}
    \item \textbf{Contesto:} Abbiamo una partizione dello spazio campionario $\{B_1, \dots, B_n\}$ (le possibili cause/scenari). Osserviamo un effetto A. Vogliamo sapere qual è la probabilità della i-esima causa, $B_i$, dato che abbiamo osservato A.
\end{itemize}
\begin{formulabox}[title={Teorema di Bayes (forma generale)}]
    \[ P(B_i|A) = \frac{P(A|B_i)P(B_i)}{\sum_{j=1}^{n} P(A|B_j)P(B_j)} \]
\end{formulabox}
\begin{itemize}
    \item \textbf{Numeratore:} È la probabilità che si verifichino sia la causa $B_i$ che l'effetto A, ovvero $P(A \cap B_i)$.
    \item \textbf{Denominatore:} È la probabilità che si verifichi l'effetto A, calcolata sommando su tutte le possibili cause (è la formula delle probabilità totali).
    \item \textbf{In pratica:} La probabilità della causa $i$ dato l'effetto, è il "contributo" della causa $i$ al verificarsi dell'effetto, diviso il "contributo" di tutte le cause messe insieme.
\end{itemize}

\section{Indipendenza degli Eventi}

\begin{definizione}
Due eventi A e B sono \textbf{indipendenti} se il verificarsi di uno non dà alcuna informazione sul verificarsi dell'altro. Sapere che B è accaduto non cambia in alcun modo la probabilità di A.
\[ \text{Se A e B sono indipendenti, allora } P(A|B) = P(A) \]
\end{definizione}

\begin{regola}[Formula pratica per l'indipendenza]
Sostituendo $P(A|B) = P(A)$ nella formula moltiplicativa $P(A \cap B) = P(A|B)P(B)$, otteniamo la definizione formale di indipendenza. Due eventi A e B sono indipendenti se:
\begin{formulabox}
    $P(A \cap B) = P(A)P(B)$
\end{formulabox}
\textit{Notiamo quindi che la probabilità che 2 eventi indipendenti accadano contemporaneamente è semplicemente il prodotto delle probabilità individuali.}
\end{regola}

\subsubsection*{Implicazioni dell'indipendenza}
La definizione di indipendenza è coerente con quella di probabilità condizionata.
\begin{formulabox}
    \begin{align*}
        P(A|B) &= \frac{P(A \cap B)}{P(B)} = \frac{P(A)P(B)}{P(B)} = P(A) \\
        P(B|A) &= \frac{P(B \cap A)}{P(A)} = \frac{P(B)P(A)}{P(A)} = P(B)
    \end{align*}
\end{formulabox}
\textbf{Spiegazione:} Questo passaggio conferma la nostra intuizione iniziale. Se 2 eventi sono indipendenti, conoscere l'esito di uno non cambia la probabilità dell'altro. La probabilità condizionata collassa sulla probabilità "base" $P(A)$.
\begin{itemize}
    \item Si osserva anche che se A e B sono indipendenti, allora lo sono anche $A^c$ con B, A con $B^c$ e $A^c$ con $B^c$. L'indipendenza si estende a tutte le combinazioni degli eventi e dei loro complementari.
\end{itemize}

\begin{tcolorbox}[colback=red!10!white, colframe=red!75!black, title=ATTENZIONE: Eventi Disgiunti e Indipendenti sono DIVERSI]
\begin{itemize}
    \item \textbf{Disgiunti $\rightarrow A \cap B = \emptyset$}. Se sai che A è accaduto, allora sei certo che B \textbf{non} può accadere ($P(B|A) = 0$). Questa è la forma più "forte" di dipendenza.
    \item \textbf{Indipendenti $\rightarrow$} Sapere che A è accaduto, non cambia per nulla la probabilità di B ($P(B|A) = P(B)$).
\end{itemize}
L'unica possibilità che 2 eventi possano essere sia disgiunti che indipendenti è se almeno uno dei due ha probabilità zero.
\end{tcolorbox}

\subsubsection*{Indipendenza di 3 o più eventi}
L'indipendenza può essere estesa a più di 2 eventi, ma la definizione diventa più stringente. \\
3 eventi A, B, e C sono indipendenti se sono verificate \textbf{tutte e quattro} le seguenti condizioni:
\begin{enumerate}
    \item $P(A \cap B \cap C) = P(A)P(B)P(C)$
    \item $P(A \cap B) = P(A)P(B)$
    \item $P(A \cap C) = P(A)P(C)$
    \item $P(B \cap C) = P(B)P(C)$
\end{enumerate}
\textit{Non basta che gli eventi siano indipendenti "a due a due", è necessaria anche la prima condizione, che riguarda l'intersezione di tutti e 3. L'idea si può generalizzare ad n eventi: bisogna verificare che la regola del prodotto valga per tutte le possibili sotto-intersezioni.}

\newpage

\section{Definizione delle Variabili Aleatorie}
Una variabile aleatoria è una quantità numerica il cui valore dipende dall'esito di un esperimento aleatorio.

\begin{definizione}[Variabile Aleatoria (v.a.)]
Una variabile aleatoria (abbreviata con v.a. o r.v. in inglese) non è "variabile" nel senso di incognita algebrica, né "aleatoria" nel senso di caotica. È una \textbf{funzione} che associa un numero reale ad ogni esito dello spazio campionario S.
\end{definizione}

\begin{esempio}
\
\begin{itemize}
    \item \textbf{Esperimento:} Lancio di 2 monete. $S = \{TT, CC, TC, CT\}$
    \item \textbf{Variabile aleatoria X:} "Numero di teste"
    \item \textbf{X è una funzione che mappa:}
    \begin{itemize}
        \item $TT \rightarrow 2$
        \item $TC \rightarrow 1$
        \item $CT \rightarrow 1$
        \item $CC \rightarrow 0$
    \end{itemize}
    \item Invece di parlare dell'evento $\{TC, CT\}$, ora possiamo parlare dell'evento $\{X=1\}$. Abbiamo trasformato un problema su insiemi in un problema su numeri.
\end{itemize}
\end{esempio}

\subsubsection*{Notazione}
\begin{itemize}
    \item \textbf{X (maiuscola):} Rappresenta la v.a. stessa, la "regola" o la "funzione". È l'oggetto concettuale ("il numero totale di successi").
    \item \textbf{x (minuscola):} Rappresenta una specifica realizzazione numerica, un valore che la variabile può assumere (come 2, 5, 10.3, ...).
\end{itemize}

\subsection{Variabili Aleatorie Discrete}
\begin{definizione}
Una v.a. si dice \textbf{discreta} se i valori che può assumere sono in numero finito o al più numerabile. I valori che una v.a. discreta assume sono "separati", "contabili", come i gradini di una scala.
\begin{itemize}
    \item Possono essere finiti (es. i risultati di un dado: $\{1,2,3,4,5,6\}$)
    \item O infiniti ma enumerabili (es. il n° di email che ricevi in un'ora: $\{0, 1, 2, \dots\}$ all'infinito).
\end{itemize}
\end{definizione}

\subsubsection{Funzione di massa di probabilità $p(x)$}
\begin{definizione}
Per una v.a. discreta possiamo definire una funzione, $p(x)$, che dà la probabilità associata a ciascun singolo valore $x$ che la variabile può assumere. È una sorta di "distribuzione dei pesi" della probabilità totale tra i valori possibili.
\begin{formulabox}
    $p(x) = P(X=x)$
\end{formulabox}
\end{definizione}

\subsection{Proprietà della Funzione di Massa di Probabilità p(x)}
\begin{enumerate}
    \item $p(x) \ge 0$ per ogni $x$. (Le probabilità non possono essere negative).
    \item $\sum p(x) = 1$. (Sommando le probabilità su \textbf{tutti} i possibili valori di $x$, dobbiamo ottenere 1, perché è certo che la v.a. assumerà uno dei suoi valori possibili).
\end{enumerate}

\subsubsection*{Calcolare la probabilità di un evento A}
Se A è un insieme di valori possibili (es. $A = \{2, 4, 6\}$), allora:
\[ P(X \in A) = p(2) + p(4) + p(6) \]
Basta sommare le probabilità (i "pesi") dei singoli valori che compongono l'evento.

\begin{esempio}[Funzione di Massa di Probabilità]
Immagina di avere un'urna che contiene 5 palline:
\begin{itemize}
    \item 3 palline sono rosse e hanno il numero 1 scritto sopra.
    \item 2 palline sono blu e hanno il numero 2 scritto sopra.
\end{itemize}
Eseguiamo un esperimento: estraiamo 2 palline dall'urna senza reinserirle. \\
Definiamo la v.a. X come la \textbf{somma} dei numeri sulle 2 palline estratte.

\textbf{Descriviamo la funzione di massa di probabilità $p(x)$ per la v.a. X.}

La nostra v.a. può assumere i valori: $X \in \{2, 3, 4\}$.
Calcoliamo ora $p(2)$, $p(3)$, e $p(4)$.

\begin{itemize}
    \item \textbf{Spazio campionario:} Il numero totale di modi per scegliere 2 palline da 5 è $|S| = \binom{5}{2} = \frac{5 \cdot 4}{2} = 10$. Questo calcolo va bene perché non ci interessa l'ordine e non reinseriamo.

    \item \textbf{Calcolo di $p(2) = P(X=2)$:} \\
    L'unico modo per ottenere somma 2 è estrarre due palline con il numero 1. Ci sono 3 palline rosse (con "1"), quindi il numero di modi per sceglierne 2 è $\binom{3}{2} = 3$.
    \[ p(2) = \frac{\binom{3}{2}}{\binom{5}{2}} = \frac{3}{10} \]

    \item \textbf{Calcolo di $p(4) = P(X=4)$:} \\
    L'unico modo per ottenere somma 4 è estrarre due palline con il numero 2. Ci sono 2 palline blu (con "2"), quindi il numero di modi per sceglierne 2 è $\binom{2}{2} = 1$.
    \[ p(4) = \frac{\binom{2}{2}}{\binom{5}{2}} = \frac{1}{10} \]

    \item \textbf{Calcolo di $p(3) = P(X=3)$:} \\
    L'unico modo per ottenere somma 3 è estrarre una pallina rossa (con "1") e una blu (con "2"). Il numero di modi è $\binom{3}{1} \cdot \binom{2}{1} = 3 \cdot 2 = 6$.
    \[ p(3) = \frac{\binom{3}{1}\binom{2}{1}}{\binom{5}{2}} = \frac{6}{10} \]
\end{itemize}
Verifica: $p(2)+p(3)+p(4) = \frac{3}{10} + \frac{6}{10} + \frac{1}{10} = \frac{10}{10} = 1$.
\end{esempio}

\newpage

\section{Variabili Aleatorie Continue}
\begin{definizione}
Una v.a. \textbf{continua} è una v.a. che può assumere infiniti valori reali all'interno di un intervallo continuo. A differenza delle v.a. discrete, che prendono valori isolati (come 0,1,2,...), una v.a. continua può assumere \textbf{qualsiasi} valore reale in un intervallo, ad esempio tra 0 e 1, o tra $-\infty$ e $+\infty$.
\end{definizione}

\subsection*{Il problema delle v.a. continue}
Se X è una v.a. continua (es. l'altezza di una persona a caso), qual è la probabilità che sia \textit{esattamente} 175,0000... cm? \\
Poiché ci sono infiniti valori possibili, la probabilità di trovarne uno esatto è 0.
\[ P(X=x) = 0 \]
Questo significa che la funzione di massa $p(x)$ non ha più senso per le continue. Ci serve un nuovo strumento.

\subsection{La funzione di densità $f(x)$}
Per una v.a. continua, esiste una funzione, $f(x)$, chiamata \textbf{densità}, tale che la probabilità che X cada in un insieme (intervallo) A è data dall'area sotto la curva di $f(x)$ in quell'intervallo.
\begin{formulabox}
    \[ P(X \in A) = \int_A f(x)dx \]
\end{formulabox}
\textit{Nota: non chiediamo più $P(X=x)$, ma $P(a \le X \le b)$}.

\subsubsection*{Proprietà della funzione di densità}
\begin{enumerate}
    \item $f(x) \ge 0$: La densità non può essere negativa (la curva sta sempre sopra l'asse x).
    \item $\int_{-\infty}^{+\infty} f(x)dx = 1$: L'area totale sotto l'intera curva deve essere 1. Questo è l'analogo di $\sum p(x)=1$ per le discrete.
\end{enumerate}
$f(x)$ misura quindi la "densità" di probabilità intorno ad un punto $x$. Dove $f(x)$ è alta, è più probabile trovare valori di X; dove è bassa, è meno probabile.

\begin{esempio}[Funzione di densità]
Immagina un gioco molto semplice. C'è un timer che parte da 0 e si ferma in un istante di tempo casuale, ma non oltre i 2 secondi. L'istante esatto in cui si ferma, X, può essere qualsiasi numero reale tra 0 e 2. Supponiamo che il meccanismo sia "semplice" e non abbia "preferenze", cioè che la densità di probabilità sia \textbf{costante} in questo intervallo [0, 2].
X = istante di tempo in cui il timer si ferma. X è una v.a. continua. \\
\textbf{Dobbiamo trovare la sua funzione di densità $f(x)$.}

\begin{tcolorbox}[colback=gray!10, colframe=black, title=Passaggi per la soluzione]
\begin{enumerate}
    \item \textbf{Definire il "supporto":} Il supporto è l'intervallo dove la v.a. può esistere. Qui è $[0, 2]$. Al di fuori, $f(x)=0$. Dobbiamo capire quanto vale $f(x)$ all'interno di $[0, 2]$.

    \item \textbf{Usare la regola dell'area totale:} Abbiamo ipotizzato una densità costante $f(x)=c$ per $x \in [0, 2]$. Sappiamo che l'area totale deve essere 1.
    \[ \int_{0}^{2} f(x)dx = \int_{0}^{2} c \, dx = 1 \]

    \item \textbf{Risolvere l'integrale:}
    \[ [cx]_0^2 = c(2) - c(0) = 2c = 1 \implies c = \frac{1}{2} \]

    \item \textbf{Scrivere la funzione completa:}
    \[ f(x) =
    \begin{cases}
    1/2 & \text{se } 0 \le x \le 2 \\
    0 & \text{altrimenti}
    \end{cases}
    \]
    Questa si chiama \textbf{Distribuzione Uniforme} sull'intervallo $[0, 2]$.
\end{enumerate}
\end{tcolorbox}
\end{esempio}

\section{Valore Atteso (o Media)}
Ora introduciamo un modo per sintetizzare un'intera distribuzione (sia essa discreta o continua) in un singolo numero che rappresenti il "centro di massa" o il valore "tipico".

\subsection{Definizione per v.a. discrete}
\begin{definizione}
Il \textbf{valore atteso} di una v.a. discreta X, denotato con $E(X)$ o $\mu$, è la somma di tutti i possibili valori di $x$ ponderati per la loro probabilità.
\begin{formulabox}
    $E(X) = \sum_{x} x \cdot p(x)$
\end{formulabox}
Il valore atteso è una \textbf{media ponderata}. Ogni possibile valore $x$ viene "pesato" per la sua probabilità $p(x)$. I valori più probabili contribuiscono di più alla media.
\end{definizione}

\begin{esempio}[Lancio di un dado]
Sia X il risultato del lancio. I valori possibili sono $\{1, 2, 3, 4, 5, 6\}$, ognuno con $p(x) = 1/6$.
\[ E(X) = 1\left(\frac{1}{6}\right) + 2\left(\frac{1}{6}\right) + 3\left(\frac{1}{6}\right) + 4\left(\frac{1}{6}\right) + 5\left(\frac{1}{6}\right) + 6\left(\frac{1}{6}\right) = \frac{21}{6} = 3.5 \]
Notare che il valore 3.5 non è un valore che il dado può assumere; è la media dei valori se lanciassimo il dado un numero infinito di volte.
\end{esempio}

\subsection{Definizione per v.a. continue}
\begin{definizione}
Il concetto è identico: è una media ponderata. Ma siccome abbiamo una distribuzione continua, la somma ($\sum$) viene sostituita dall'integrale ($\int$). Ogni valore $x$ sull'asse reale viene pesato per la sua densità $f(x)$.
\begin{formulabox}
    $E(X) = \int_{-\infty}^{+\infty} x \cdot f(x) \, dx$
\end{formulabox}
\end{definizione}

\newpage

\section{Valore Atteso di una Funzione di una v.a.}
E se fossimo interessati non alla media di X, ma alla media di $X^2$ o $\log(X)$?
Chiamiamo $g(X)$ una funzione della variabile aleatoria X.

La regola è semplice: invece di pesare $x$ con la sua probabilità/densità, pesiamo $g(x)$.

\begin{regola}[LOTUS - Law of the Unconscious Statistician]
\
\begin{itemize}
    \item \textbf{Discrete:}
    \begin{formulabox}
        $E[g(X)] = \sum_x g(x) \cdot p(x)$
    \end{formulabox}

    \item \textbf{Continue:}
    \begin{formulabox}
        $E[g(X)] = \int_{-\infty}^{+\infty} g(x) \cdot f(x) \, dx$
    \end{formulabox}
\end{itemize}
\end{regola}
\begin{tcolorbox}[colback=green!5!white, colframe=green!60!black, title=Importanza di LOTUS]
La regola per calcolare $E[g(X)]$ è una delle proprietà più potenti del valore atteso. Ci permette di calcolare la media di una variabile trasformata \textbf{senza} doverne prima derivare la distribuzione.
\end{tcolorbox}

\begin{esempio}[Vincita media di un gioco]
\textbf{Scenario di Base:} Riprendiamo il nostro esempio del lancio di un dado.
\begin{itemize}
    \item Esperimento: Lancio di un dado a 6 facce, non truccato.
    \item Variabile Aleatoria X: il numero che esce.
    \item Valori possibili di X: $\{1, 2, 3, 4, 5, 6\}$.
    \item Funzione di massa $p(x)$: $p(x) = 1/6$ per ciascuno di questi valori.
    \item Valore medio di X: $E(X) = 3.5$.
\end{itemize}
\textbf{Lo Scenario con $g(x)$:} Ora, immaginiamo un gioco basato sul lancio di questo dado.
\begin{itemize}
    \item \textbf{Il gioco:} Vinci un ammontare in euro pari al \textbf{QUADRATO} del numero uscito.
    \item Vogliamo calcolare la \textbf{vincita media} di questo gioco.
    \item La vincita non è più X, ma una funzione di X, $g(x) = X^2$.
    \item Vogliamo calcolare $E[g(X)] = E(X^2)$.
\end{itemize}

\textbf{Metodo 1: Lento ma Intuitivo (Creare una nuova v.a. Y = $X^2$)}
\begin{enumerate}
    \item I valori possibili di Y sono $\{1^2, 2^2, \dots, 6^2\} = \{1, 4, 9, 16, 25, 36\}$.
    \item La probabilità di ciascun valore di Y è $p(y)=1/6$.
    \item Calcoliamo $E(Y)$:
    \[ E(Y) = 1\left(\frac{1}{6}\right) + 4\left(\frac{1}{6}\right) + \dots + 36\left(\frac{1}{6}\right) = \frac{91}{6} \approx 15.17 \]
\end{enumerate}

\textbf{Metodo 2: Veloce e Diretto (Usando LOTUS)}
Applichiamo direttamente la formula $E[g(X)] = \sum g(x)p(x)$:
\begin{align*}
    E(X^2) &= \sum_{x=1}^{6} x^2 \cdot p(x) \\
            &= 1^2\left(\frac{1}{6}\right) + 2^2\left(\frac{1}{6}\right) + 3^2\left(\frac{1}{6}\right) + 4^2\left(\frac{1}{6}\right) + 5^2\left(\frac{1}{6}\right) + 6^2\left(\frac{1}{6}\right) \\
            &= \frac{1+4+9+16+25+36}{6} = \frac{91}{6} \approx 15.17
\end{align*}
Come vedi, il risultato è identico, ma il calcolo è stato più diretto.
\end{esempio}

\section{Varianza di una Variabile Aleatoria}

\subsection{Un caso speciale: $E(X^2)$}
Da questo arriviamo quindi alla formula per il calcolo di $E(X^2)$, che è un'applicazione diretta di $E[g(X)]$ dove la funzione di trasformazione è semplicemente $g(x) = x^2$.
\begin{itemize}
    \item \textbf{V.A. Discrete:} Per calcolare $E(X^2)$, prendi ogni possibile valore $x$ che la variabile X può assumere, lo elevi al quadrato, lo moltiplichi per la probabilità di quel valore $p(x)$, e sommi i prodotti.
    \begin{formulabox}
        $E(X^2) = \sum_x x^2 p(x)$
    \end{formulabox}

    \item \textbf{V.A. Continue:} Il concetto è identico, ma la somma ($\sum$) viene sostituita da un integrale ($\int$).
    \begin{formulabox}
        $E(X^2) = \int_{-\infty}^{+\infty} x^2 f(x) \, dx$
    \end{formulabox}
\end{itemize}

\subsection{Proprietà del valore medio}
\begin{enumerate}
    \item \textbf{Proprietà di Linearità:}
    \begin{formulabox}
        $E(aX + b) = aE(X) + b$
    \end{formulabox}
    Questa è una proprietà importantissima. Se trasformi la tua v.a. X moltiplicandola per una costante $a$ e sommando una costante $b$, il nuovo valore medio è semplicemente il vecchio valore medio trasformato allo stesso modo.

    \item \textbf{Additività del valore:}
    \begin{formulabox}
        $E(X+Y) = E(X) + E(Y)$
    \end{formulabox}
    Il valore medio della somma di due v.a. (anche se non indipendenti) è la somma dei loro valori medi. Questa proprietà è incredibilmente generale e utile.

    \item \textbf{Valore atteso della funzione $g(x)$:} Questo punto ribadisce quello che abbiamo discusso: $E[g(X)]$ si calcola come media di $g(x)$ pesata con le probabilità di X.
\end{enumerate}

\subsection{La Varianza: $Var(X)$}
Il valore medio ci dice il "centro" di una distribuzione, ma non ci dice nulla su quanto i valori siano \textit{sparpagliati} attorno a questo centro.

\begin{definizione}[Varianza]
\textbf{L'idea:} Misurare lo scarto dalla media.
\begin{enumerate}
    \item Per ogni possibile valore $x$, calcoliamo lo \textbf{scarto dalla media}: $(x-\mu)$, dove $\mu = E(X)$.
    \item Questo scarto può essere positivo o negativo. Se facessimo la media degli scarti, $E(X-\mu)$, otterremmo sempre 0. Non è utile.
    \item \textbf{SOLUZIONE:} Eleviamo gli scarti al quadrato: $(x-\mu)^2$. In questo modo sono tutti non negativi.
    \item Ora calcoliamo il valore medio di questi \textbf{scarti quadratici}. Questa è la \textbf{VARIANZA}.
\end{enumerate}
\begin{formulabox}
    $Var(X) = E[(X-\mu)^2]$
\end{formulabox}
È il valore atteso dello scarto quadratico dalla media.
\end{definizione}

\subsubsection{Formula computazionale della Varianza}
\begin{align*}
    Var(X) &= E[(X-\mu)^2] \\
           &= E[X^2 - 2\mu X + \mu^2] && \text{(espandendo il quadrato)} \\
           &= E(X^2) - E(2\mu X) + E(\mu^2) && \text{(per linearità della media)} \\
           &= E(X^2) - 2\mu E(X) + \mu^2 && \text{(poiché $2\mu$ e $\mu^2$ sono costanti)} \\
           &= E(X^2) - 2\mu \cdot \mu + \mu^2 && \text{(poiché $E(X)=\mu$)} \\
           &= E(X^2) - 2\mu^2 + \mu^2 = E(X^2) - \mu^2
\end{align*}
\begin{formulabox}
    $Var(X) = E(X^2) - [E(X)]^2$
\end{formulabox}
\textit{La varianza è la media dei quadrati meno il quadrato della media.}

\subsubsection*{Riassunto del calcolo della Varianza}
\begin{enumerate}
    \item Calcola la media: $\mu = E(X)$.
    \item Calcola la media dei quadrati: $E(X^2)$ (usando le formule $\sum x^2 p(x)$ o $\int x^2 f(x)dx$).
    \item Sottrai: $Var(X) = E(X^2) - \mu^2$.
\end{enumerate}

\subsubsection*{Proprietà fondamentale della varianza}
\begin{itemize}
    \item $Var(X) \ge 0$. Poiché è una media di quadrati, la varianza non può mai essere negativa.
    \item $Var(X)=0$ se e solo se X non è affatto "aleatoria", ma è una costante.
\end{itemize}

\newpage

\section{Distribuzioni Congiunte}
Finora abbiamo studiato una v.a. alla volta (es. il risultato di un dado). Ma cosa succede se lanciamo 2 dadi e siamo interessati sia al punteggio più alto (X) che a quello più basso (Y)? X e Y sono 2 v.a. definite sullo stesso esperimento e probabilmente sono dipendenti tra loro. Come descriviamo questa relazione?

\subsection{Funzione di massa congiunta $p_{X,Y}(x,y)$}
\begin{definizione}
Questa funzione dà la probabilità che \textbf{contemporaneamente} la v.a. X assuma il valore $x$ \textbf{e} la v.a. Y assuma il valore $y$.
\begin{formulabox}
    $p_{X,Y}(x,y) = P(X=x, Y=y)$
\end{formulabox}
Mentre $p(x)$ era una lista di probabilità, $p_{X,Y}(x,y)$ è una \textbf{tabella} a doppia entrata. Le righe possono rappresentare i valori di X, le colonne i valori di Y, ed ogni cella $(x,y)$ contiene la probabilità che si verifichi quella specifica coppia di valori.
\end{definizione}

\subsection{Distribuzioni marginali}
Abbiamo la tabella congiunta $p_{X,Y}(x,y)$, che contiene tutte le informazioni sulla coppia $(X,Y)$. Come possiamo recuperare da essa la distribuzione della sola X (o della sola Y), ignorando l'altra variabile?

\begin{definizione}[Funzione di massa marginale]
Per trovare la probabilità totale che $X$ assuma un certo valore $x$, dobbiamo considerare tutti i modi in cui questo può accadere, indipendentemente da cosa faccia $Y$. Questo significa sommare tutte le probabilità lungo la riga (o colonna) corrispondente a quel valore $x$ nella nostra tabella congiunta.
\begin{itemize}
    \item \textbf{Marginale di X (somma lungo le colonne per ogni riga):}
    \begin{formulabox}
        $p_X(x) = P(X=x) = \sum_{y} p_{X,Y}(x,y)$
    \end{formulabox}

    \item \textbf{Marginale di Y (somma lungo le righe per ogni colonna):}
    \begin{formulabox}
        $p_Y(y) = P(Y=y) = \sum_{x} p_{X,Y}(x,y)$
    \end{formulabox}
\end{itemize}
\end{definizione}

\begin{esempio}[Lancio di due dadi]
Sia X il punteggio più basso e Y il punteggio più alto. Vogliamo calcolare $p_X(1) = P(X=1)$.
Questo può accadere in 11 modi: $(1,1), (1,2), \dots, (1,6)$ e $(2,1), \dots, (6,1)$.
La probabilità di ogni singola coppia $(x,y)$ con dadi standard è $1/36$.
\begin{align*}
p_X(1) &= p_{X,Y}(1,1) + p_{X,Y}(1,2) + \dots + p_{X,Y}(1,6) \\
&= \frac{1}{36} + \frac{2}{36} + \frac{2}{36} + \frac{2}{36} + \frac{2}{36} + \frac{2}{36} = \frac{11}{36}
\end{align*}
\end{esempio}

\subsection{Indipendenza tra Variabili Aleatorie}
Questo è il caso speciale che ci permette di ricostruire la congiunta dalle marginali.

\begin{definizione}
Due v.a. X e Y sono \textbf{indipendenti} se conoscere il valore di una non dà alcuna informazione sul valore dell'altra. \\
In pratica, X e Y sono indipendenti se per ogni possibile coppia $(x,y)$, la probabilità congiunta è il prodotto delle probabilità marginali.
\begin{formulabox}
    $p_{X,Y}(x,y) = p_X(x) \cdot p_Y(y)$
\end{formulabox}
Questa è l'estensione diretta della definizione di indipendenza degli eventi.
\end{definizione}

\subsection{Valore atteso di una funzione congiunta $E[g(X,Y)]$}
Questo estende l'idea di $E[g(X)]$ a 2 variabili. Se abbiamo una funzione $g$ che dipende sia da X che da Y, il suo valore atteso si calcola:
\begin{formulabox}
    $E[g(X,Y)] = \sum_x \sum_y g(x,y) \cdot p_{X,Y}(x,y)$
\end{formulabox}
\textit{In pratica: per ogni cella $(x,y)$ della tabella, calcoli $g(x,y)$, lo moltiplichi per la probabilità di quella cella $p_{X,Y}(x,y)$, e poi sommi i risultati di tutte le celle.}

\newpage

\subsubsection{Conseguenze dirette dell'indipendenza}
Se X e Y sono indipendenti, allora:
\begin{formulabox}
    $E(XY) = E(X)E(Y)$
\end{formulabox}
Questo è un teorema fondamentale. Se 2 v.a. sono indipendenti, la media del loro prodotto è semplicemente il prodotto delle loro medie.

\begin{tcolorbox}[colback=red!10!white, colframe=red!75!black, title=Attenzione]
Il contrario \textbf{non} è vero in generale! Se $E(XY)=E(X)E(Y)$, non è detto che X e Y siano indipendenti. Questa condizione è meno forte dell'indipendenza.
\end{tcolorbox}

\subsection{Covarianza: $Cov(X,Y)$}
Vogliamo un indice che ci dica se, quando X è sopra la sua media, anche Y tende ad essere sopra la sua media (\textbf{relazione positiva}) o se tende ad essere sotto la sua media (\textbf{relazione negativa}).

\begin{definizione}[Covarianza]
\begin{enumerate}
    \item Prendiamo gli scarti di X dalla sua media: $(X - E(X))$.
    \item Prendiamo gli scarti di Y dalla sua media: $(Y - E(Y))$.
    \item Moltiplichiamo questi scarti: $(X - E(X))(Y - E(Y))$.
    \begin{itemize}
        \item Se X e Y sono entrambi sopra la media, il prodotto è $(+) \cdot (+) = (+)$.
        \item Se X e Y sono entrambi sotto la media, il prodotto è $(-) \cdot (-) = (+)$.
        \item Se uno è sopra e l'altro è sotto, il prodotto è $(+) \cdot (-) = (-)$.
    \end{itemize}
    \item Calcoliamo la media di questi prodotti. Questa è la \textbf{COVARIANZA}.
\end{enumerate}
\begin{formulabox}
    $Cov(X,Y) = E[(X-E(X))(Y-E(Y))]$
\end{formulabox}
\end{definizione}

\subsubsection*{Formula computazionale}
\begin{formulabox}
    $Cov(X,Y) = E(XY) - E(X)E(Y)$
\end{formulabox}
\textit{La covarianza è la media del prodotto meno il prodotto delle medie.}

\subsubsection*{Interpretazione del segno della Covarianza}
\begin{itemize}
    \item \textbf{$Cov(X,Y) > 0$:} C'è una relazione lineare \textbf{positiva}. In media, a valori alti di X corrispondono valori alti di Y.
    \item \textbf{$Cov(X,Y) < 0$:} C'è una relazione lineare \textbf{negativa}. In media, a valori alti di X corrispondono valori bassi di Y.
    \item \textbf{$Cov(X,Y) = 0$:} Non c'è relazione \textbf{lineare}. Le variabili sono \textbf{scorrelate}.
\end{itemize}

\section{Correlazione}
\subsection{Proprietà importanti della Covarianza}
\begin{enumerate}
    \item \textbf{$Cov(X,X) = Var(X)$} \\
    Se calcoliamo la covarianza di una v.a. con se stessa, otteniamo la varianza. Questo perché:
    \[ Cov(X,X) = E(X \cdot X) - E(X)E(X) = E(X^2) - [E(X)]^2 = Var(X) \]

    \item \textbf{Se X e Y sono indipendenti, allora $Cov(X,Y) = 0$} \\
    Se X e Y sono indipendenti, sappiamo che $E(XY) = E(X)E(Y)$. Sostituendo nella formula computazionale della covarianza:
    \[ Cov(X,Y) = E(XY) - E(X)E(Y) = E(X)E(Y) - E(X)E(Y) = 0 \]

    \item \textbf{Variabili Indipendenti $\implies$ Variabili Scorrelate} \\
    L'implicazione opposta non è sempre vera.
    \[ \text{Ind} \implies \text{Scorr (Cov=0)} \quad (\text{Sempre Vero}) \]
    \[ \text{Scorr (Cov=0)} \implies \text{Ind} \quad (\text{Falso in generale}) \]
    Questo perché la covarianza misura solo la forza della relazione \textbf{lineare}. Due v.a. possono avere una relazione forte ma non-lineare ed avere comunque $Cov=0$. L'indipendenza è un concetto molto più forte, che implica l'assenza di qualsiasi tipo di relazione.
\end{enumerate}

\subsection{Normalizzazione della covarianza: la Correlazione}
La covarianza ha un problema: dipende dall'unità di misura delle variabili. Il suo valore numerico non è facilmente interpretabile.
\begin{itemize}
    \item \textbf{In sintesi:} La covarianza ci dà il \textbf{segno} (la direzione) della relazione lineare, ma il suo \textbf{valore assoluto} non ci dice nulla sulla \textbf{forza} di tale relazione in modo standardizzato.
\end{itemize}
Per risolvere questo problema, "normalizziamo" la covarianza, cioè la dividiamo per un fattore che tiene conto della dispersione delle singole variabili.

\begin{definizione}[Coefficiente di Correlazione]
\begin{formulabox}
    $Corr(X,Y) = \rho_{X,Y} = \frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}$
\end{formulabox}
Il denominatore è il prodotto delle deviazioni standard di X e Y. (La deviazione standard, $\sigma_X = \sqrt{Var(X)}$, è semplicemente la radice quadrata della varianza e ha la stessa unità di misura della variabile originale).
\end{definizione}

\subsubsection*{Proprietà del Coefficiente di Correlazione}
\begin{enumerate}
    \item È un numero puro, \textbf{senza unità di misura}. Poiché dividiamo un'unità di misura (es. $kg \cdot m$) per un'altra identica, le unità si cancellano. Questo lo rende un indice universale.
    \item È sempre compreso tra -1 e +1: $-1 \le Corr(X,Y) \le +1$.
    \begin{itemize}
        \item \textbf{$Corr(X,Y) \approx +1$}: Forte correlazione lineare \textbf{positiva}. I punti su un grafico a dispersione tendono a disporsi quasi perfettamente su una retta crescente.
        \item \textbf{$Corr(X,Y) \approx -1$}: Forte correlazione lineare \textbf{negativa}. I punti tendono a disporsi su una retta decrescente.
        \item \textbf{$Corr(X,Y) \approx 0$}: Relazione lineare debole o assente. (Questo non esclude relazioni non-lineari!).
    \end{itemize}
    \item Vale esattamente +1 o -1 solo se c'è una relazione lineare perfetta.
    \begin{itemize}
        \item $Corr(X,Y) = 1$ se e solo se $Y = aX+b$ con $a > 0$.
        \item $Corr(X,Y) = -1$ se e solo se $Y = aX+b$ con $a < 0$.
    \end{itemize}
\end{enumerate}

\newpage

\section{Funzione di Ripartizione (CDF)}
\begin{definizione}[Cumulative Distribution Function - CDF]
La funzione di ripartizione $F_X(x)$, calcolata in un punto $x$, ci dà la probabilità \textbf{accumulata} fino a quel punto.
\begin{formulabox}
    $F_X(x) = P(X \le x)$
\end{formulabox}
Se scegli un punto $x$ sull'asse numerico, $F_X(x)$ ti dice qual è la probabilità totale che la tua v.a. X assuma un valore minore o uguale ad $x$. È una probabilità "cumulativa", che parte da 0 e arriva fino a 1.
\end{definizione}

\subsection{Caso discreto}
\begin{formulabox}
    $F_X(x) = \sum_{t \le x} p(t)$
\end{formulabox}
Il grafico di $F_X(x)$ per una v.a. discreta è una \textbf{funzione a gradini}, che fa un salto in corrispondenza di ogni valore che la v.a. può assumere. L'altezza del salto in $x_i$ è esattamente $p(x_i)$.

\subsection{Caso continuo}
\begin{formulabox}
    $F_X(x) = \int_{-\infty}^{x} f(t) dt$
\end{formulabox}
Il grafico di $F_X(x)$ per una v.a. continua è una funzione \textbf{continua} e non decrescente. Parte da 0 (a $-\infty$) e sale fino ad 1 (a $+\infty$).

\subsubsection*{Relazione inversa (importantissima)}
Se la funzione di ripartizione $F_X(x)$ è l'integrale della densità $f(x)$, allora la densità $f(x)$ è la \textbf{derivata} della funzione di ripartizione.
\begin{formulabox}
    $f(x) = F_X'(x) = \frac{d}{dx}F_X(x)$
\end{formulabox}

\section{Proprietà della Varianza}
\begin{regola}
\
\begin{formulabox}
    $Var(aX+b) = a^2 Var(X)$
\end{formulabox}
\begin{itemize}
    \item La \textbf{costante additiva $b$ sparisce!} Se aggiungi una costante $b$ a tutti i valori, stai solo "traslando" l'intera distribuzione. La sua forma e la sua dispersione non cambiano. La varianza, che misura la dispersione, rimane la stessa.
    \item La \textbf{costante moltiplicativa $a$ esce al quadrato!} La varianza misura uno scarto quadratico. Se scali la variabile di un fattore $a$, lo scarto dalla media viene scalato di $a$, ma lo scarto quadratico viene scalato di $a^2$.
\end{itemize}
\end{regola}

\subsection{Varianza di una somma di v.a.}
\begin{formulabox}
    $Var(X+Y) = Var(X) + Var(Y) + 2Cov(X,Y)$
\end{formulabox}
La varianza della somma \textbf{non} è semplicemente la somma delle varianze. C'è un termine in più che dipende da come le 2 variabili si muovono insieme.
\begin{itemize}
    \item \textbf{Il termine $2Cov(X,Y)$:}
    \begin{itemize}
        \item Se X e Y sono \textbf{positivamente correlate} ($Cov > 0$), quando X è alta anche Y tende ad essere alta. I loro movimenti si sommano, aumentando la dispersione complessiva. La covarianza aggiunge variabilità.
        \item Se X e Y sono \textbf{negativamente correlate} ($Cov < 0$), quando X è alta, Y tende ad essere bassa. I loro movimenti si "compensano" a vicenda. La loro somma $X+Y$ tenderà ad essere più stabile e meno dispersa. La covarianza negativa riduce la variabilità totale.
    \end{itemize}
\end{itemize}

\subsubsection*{Caso speciale (importantissimo): X e Y scorrelate}
Se X e Y sono scorrelate, allora $Cov(X,Y)=0$.
\begin{formulabox}
    Se $Cov(X,Y)=0$, allora $Var(X+Y) = Var(X) + Var(Y)$
\end{formulabox}
\textit{Solo in questo caso speciale (che include anche il caso in cui X e Y sono indipendenti), la varianza della somma è la somma delle varianze.}

\newpage

\section{Classi Notevoli di Variabili Aleatorie}

\subsection{Variabile Aleatoria di Bernoulli}
È il modello matematico per un \textbf{singolo} esperimento che ha solo 2 possibili esiti. Per convenzione li chiamiamo \textbf{successo (1)} e \textbf{insuccesso (0)}.

\begin{itemize}
    \item \textbf{Parametro:} Ha un solo parametro, $p$, che è la probabilità di successo. Si scrive $X \sim Bernoulli(p)$.

    \item \textbf{Funzione di massa $p(x)$:}
    \begin{itemize}
        \item $P(X=1) = p$
        \item $P(X=0) = 1-p$
    \end{itemize}

    \item \textbf{Valore atteso $E(X)$:}
    \[ E(X) = 1 \cdot p + 0 \cdot (1-p) = p \]
    La media di una Bernoulli è semplicemente la sua probabilità di successo.

    \item \textbf{Varianza $Var(X)$:}
    \begin{itemize}
        \item Prima calcoliamo $E(X^2)$: $E(X^2) = 1^2 \cdot p + 0^2 \cdot (1-p) = p$.
        \item Poi uso la formula $Var(X) = E(X^2) - [E(X)]^2 = p - p^2 = p(1-p)$.
    \end{itemize}
    \begin{formulabox}
        $E(X)=p, \quad Var(X)=p(1-p)$
    \end{formulabox}
\end{itemize}
Modella il lancio di una moneta, la risposta ad una domanda sì/no, ...

\subsection{Variabile Aleatoria Binomiale}
È il modello matematico per il \textbf{numero di successi $X$ in $n$ prove di Bernoulli indipendenti ed identiche}. Stiamo sommando $n$ variabili di Bernoulli indipendenti.

\begin{itemize}
    \item \textbf{Connessione:} $X = X_1 + X_2 + \dots + X_n$, dove ogni $X_i$ è una $Bernoulli(p)$.

    \item \textbf{Parametri:} Ha 2 parametri: $n$ (numero di prove) e $p$ (probabilità di successo in ogni prova). Si scrive $X \sim Bin(n,p)$.

    \item \textbf{Funzione di massa $p(k) = P(X=k)$:}
    \begin{formulabox}
        $P(X=k) = \binom{n}{k} p^k (1-p)^{n-k}$
    \end{formulabox}

    \item \textbf{Valore atteso $E(X)$:} Invece di usare la definizione con la sommatoria, usiamo la proprietà della somma.
    \[ E(X) = E(X_1 + \dots + X_n) = E(X_1) + \dots + E(X_n) = \underbrace{p + \dots + p}_{n \text{ volte}} = np \]
    \begin{formulabox}
        $E(X) = np$
    \end{formulabox}

    \item \textbf{Varianza $Var(X)$:} Usiamo la formula per la varianza di una somma. Poiché le prove di Bernoulli sono indipendenti, le variabili $X_i$ sono indipendenti, e quindi anche scorrelate ($Cov(X_i, X_j)=0$).
    \[ Var(X) = Var(X_1 + \dots + X_n) = Var(X_1) + \dots + Var(X_n) = \underbrace{p(1-p) + \dots + p(1-p)}_{n \text{ volte}} = np(1-p) \]
    \begin{formulabox}
        $Var(X) = np(1-p)$
    \end{formulabox}
\end{itemize}

\subsection{Variabile Aleatoria di Poisson}
La distribuzione di Poisson è il modello per contare il \textbf{numero di eventi che accadono in un intervallo di tempo (o spazio) fissato}, quando questi eventi sono rari e accadono indipendentemente l'uno dall'altro.

\begin{itemize}
    \item \textbf{Valori possibili:} $X$ può assumere i valori $\{0, 1, 2, 3, \dots\}$. È una v.a. discreta con un'infinità numerabile di valori.

    \item \textbf{Parametro:} Ha un solo parametro, $\lambda$ (lambda), che rappresenta il \textbf{numero medio} di eventi nell'intervallo. $\lambda = E(X)$.

    \item \textbf{Funzione di massa $p(k) = P(X=k)$:}
    \begin{formulabox}
        $P(X=k) = e^{-\lambda} \frac{\lambda^k}{k!}$
    \end{formulabox}

    \item \textbf{Relazione con la binomiale:} La Poisson può essere vista come un'approssimazione della Binomiale quando $n$ è molto grande e $p$ è molto piccolo. In questo caso, $\lambda \approx np$.

    \item \textbf{Proprietà notevole:} Per una Poisson, \textbf{media e varianza sono uguali}.
    \begin{formulabox}
        $E(X) = \lambda, \quad Var(X) = \lambda$
    \end{formulabox}
\end{itemize}

\section{Altre Classi Notevoli di Variabili Aleatorie}

\subsection{Variabile Aleatoria Uniforme (Continua)}
È il modello per un esito che ha la stessa probabilità di cadere in qualsiasi punto di un intervallo $[a, b]$. Non ci sono "zone preferite".
\begin{itemize}
    \item \textbf{Esempio:} L'istante di tempo casuale in cui si ferma un timer tra 0 e 2 secondi.
    \item \textbf{Parametri:} I 2 estremi dell'intervallo, $a$ e $b$. Si scrive $X \sim U(a,b)$.

    \item \textbf{Funzione di densità $f(x)$:}
    Deve essere costante all'interno dell'intervallo $[a, b]$ e 0 altrove.
    L'area totale sotto la curva (che è un rettangolo) deve essere 1.
    \[ \text{Area} = \text{Base} \times \text{Altezza} = (b-a) \cdot c = 1 \implies c = \frac{1}{b-a} \]
    \begin{formulabox}
    \[ f(x) =
        \begin{cases}
        \frac{1}{b-a} & \text{se } a \le x \le b \\
        0 & \text{altrimenti}
        \end{cases}
    \]
    \end{formulabox}

    \item \textbf{Valore atteso $E(X)$:}
    \begin{formulabox}
        $E(X) = \frac{a+b}{2}$
    \end{formulabox}

    \item \textbf{Varianza $Var(X)$:}
    \begin{formulabox}
        $Var(X) = \frac{(b-a)^2}{12}$
    \end{formulabox}
    La varianza dipende solo dall'ampiezza dell'intervallo $(b-a)$. Più l'intervallo è largo, più la distribuzione è dispersa, e maggiore è la varianza.
\end{itemize}

\subsection{Variabile Aleatoria Normale (o Gaussiana)}
È la distribuzione di probabilità più importante in assoluto. Moltissimi fenomeni naturali (altezze, pesi, errori di misurazioni) seguono questa distribuzione. Il grafico è la famosa forma a \textbf{campana}.
\begin{center}
\begin{tikzpicture}
\draw[->] (-4,0) -- (4,0) node[right] {$x$};
\draw[->] (0,-0.2) -- (0,4) node[above] {$f(x)$};
\draw[thick, color=blue, domain=-3.5:3.5] plot (\x, {3*exp(-\x*\x/2)});
\draw[dashed] (0,0) -- (0,3);
\node at (0,-0.5) {$\mu$};
\draw[<->] (-1, 1.8) -- (1, 1.8);
\node at (0, 2) {$2\sigma$};
\end{tikzpicture}
\end{center}

\begin{itemize}
    \item \textbf{Parametri:} La distribuzione Normale è definita da 2 parametri:
    \begin{enumerate}
        \item \textbf{$\mu$ (mu), la media:} Questo parametro determina il \textbf{centro} della campana. È il valore atteso $E(X)$.
        \item \textbf{$\sigma^2$ (sigma quadro), la varianza:} Questo parametro determina la \textbf{forma} della campana.
        \begin{itemize}
            \item Un $\sigma^2$ grande significa molta variabilità, quindi la campana sarà larga e schiacciata.
            \item Un $\sigma^2$ piccolo significa poca variabilità, quindi la campana sarà stretta e appuntita.
            \item $\sigma$ (senza il 2) è la deviazione standard.
        \end{itemize}
    \end{enumerate}

    \item \textbf{Notazione:} Se una v.a. Normale ha media $\mu$ e varianza $\sigma^2$ scriviamo:
    \[ X \sim N(\mu, \sigma^2) \]

    \item \textbf{Funzione di densità $f(x)$:}
    \begin{formulabox}
        $f(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$
    \end{formulabox}
    Produce la curva della campana. Il grafico è simmetrico rispetto alla sua media $\mu$.
\end{itemize}

\newpage

\subsubsection{La Normale Standard ($Z$)}
Esiste una Normale Standard (Z) che funge da riferimento per tutte le altre.
\begin{itemize}
    \item È una normale con media 0 e varianza 1.
    \begin{formulabox}
        $Z \sim N(0, 1)$
    \end{formulabox}
\end{itemize}
È importante perché qualsiasi calcolo di probabilità per una qualsiasi variabile Normale $N(\mu, \sigma^2)$ può essere ricondotto ad un calcolo sulla Normale Standard $N(0, 1)$. I valori di probabilità per la Z sono tabulati in apposite tavole statistiche.

\subsubsection{Standardizzazione: da X a Z}
Se abbiamo una v.a. $X \sim N(\mu, \sigma^2)$, come la trasformiamo in una $Z \sim N(0,1)$?

\begin{itemize}
    \item \textbf{La formula inversa è: $X = \sigma Z + \mu$}. Se prendi una media Z (media 0, var 1), la "scali" di $\sigma$ e la "trasli" di $\mu$, ottieni una X (media $\mu$, var $\sigma^2$).

    \item \textbf{La Standardizzazione è:}
    \begin{formulabox}
        $Z = \frac{X-\mu}{\sigma}$
    \end{formulabox}
\end{itemize}
\begin{enumerate}
    \item \textbf{Sottrazione della media $(X-\mu)$:} Calcoliamo lo scarto di X dalla sua media. Il risultato è una nuova variabile con media 0.
    \item \textbf{Divisione per la deviazione standard $\frac{(X-\mu)}{\sigma}$:} Dividiamo questo scarto per la deviazione standard. Questo processo si chiama "riscalare" e fa sì che la nuova variabile abbia varianza (e deviazione standard) pari ad 1.
\end{enumerate}
Il risultato di questa trasformazione, $z$, viene chiamato \textbf{z-score}. Uno z-score di, es., $z=1.5$ significa che il valore originale $x$ si trova a 1.5 deviazioni standard sopra la media.
\subsection{Il Calcolo Pratico di Probabilità con la Normale}
Il problema: Vogliamo calcolare $P(a \le X \le b)$, dove $X \sim N(\mu, \sigma^2)$. Non possiamo risolvere l'integrale della densità Normale a mano.

\begin{tcolorbox}[colback=green!5!white, colframe=green!60!black, title=La strategia in 3 passi]
\begin{enumerate}
    \item \textbf{Standardizzare l'intervallo:} Applichiamo la trasformazione $z = (x - \mu) / \sigma$ a tutti e tre i membri della disuguaglianza.
    \[ P(a \le X \le b) = P\left(\frac{a-\mu}{\sigma} \le \frac{X-\mu}{\sigma} \le \frac{b-\mu}{\sigma}\right) \]
    Questo diventa: $P(z_a \le Z \le z_b)$, dove $z_a = (a-\mu)/\sigma$ e $z_b = (b-\mu)/\sigma$.

    \item \textbf{Usare la Funzione di Ripartizione della Z ($\Phi$):}
    La funzione di ripartizione della Normale Standard Z è così importante che ha un suo simbolo speciale: la lettera greca maiuscola $\Phi$ (Phi).
    \[ \Phi(z) = P(Z \le z) \]
    I valori di $\Phi(z)$ si trovano nelle tavole statistiche o si calcolano con un software. Per trovare la probabilità di un intervallo, usiamo la proprietà:
    \begin{formulabox}
        $P(z_a \le Z \le z_b) = \Phi(z_b) - \Phi(z_a)$
    \end{formulabox}

    \item \textbf{Cercare i valori sulle tavole e calcolare.}
\end{enumerate}
\end{tcolorbox}

\begin{esempio}[Altezza della popolazione]
\textbf{Setup:} L'altezza X è $N(175, 25)$. Quindi $\mu = 175$ e $\sigma^2 = 25$, il che significa $\sigma = \sqrt{25} = 5$. \\
\textbf{Domanda:} Qual è la frazione di popolazione più alta di 180cm? Vogliamo calcolare $P(X \ge 180)$.

\textbf{Svolgimento:}
\begin{enumerate}
    \item \textbf{Standardizziamo:}
    \[ P(X \ge 180) = P\left(\frac{X-175}{5} \ge \frac{180-175}{5}\right) = P(Z \ge 1) \]

    \item \textbf{Usiamo $\Phi$ e la regola del complementare:}
    Le tavole ci danno $\Phi(z) = P(Z \le z)$ (l'area a sinistra). Noi vogliamo l'area a destra.
    \[ P(Z \ge 1) = 1 - P(Z < 1) = 1 - \Phi(1) \]

    \item \textbf{Cerchiamo il valore sulle tavole:}
    Andando a cercare sulle tavole della Normale Standard, si trova che $\Phi(1) \approx 0.8413$.

    \item \textbf{Calcolo finale:}
    \[ P(X \ge 180) = 1 - 0.8413 = 0.1587 \]
    Circa il 15.87\% della popolazione è più alto di 180cm.
\end{enumerate}
\end{esempio}

\begin{esempio}[Problema Inverso]
Questo è il "gioco al contrario". Non ci viene dato un valore $x$ per calcolare una probabilità, ma ci viene data una probabilità per trovare il valore $x$ corrispondente.

\textbf{Domanda:} Trovare l'altezza $x$ tale che il 5\% della popolazione sia più bassa. Vogliamo trovare $x$ tale che $P(X \le x) = 0.05$.

\textbf{Svolgimento:}
\begin{enumerate}
    \item \textbf{Standardizziamo:}
    \[ P(X \le x) = P\left(Z \le \frac{x-175}{5}\right) = 0.05 \]
    Questo significa che: $\Phi\left(\frac{x-175}{5}\right) = 0.05$.

    \item \textbf{Usiamo le tavole al contrario (Tavole dei Quantili):}
    Dobbiamo trovare quale z-score ha un'area alla sua sinistra pari a 0.05. Questo valore si chiama \textbf{quantile}. Cercando 0.05 all'interno della tabella (o usando la simmetria), si trova che lo z-score cercato è $z \approx -1.645$.

    \item \textbf{Risolviamo per x:}
    \[ \frac{x-175}{5} = -1.645 \]
    \[ x - 175 = 5 \cdot (-1.645) = -8.225 \]
    \[ x = 175 - 8.225 = 166.775 \]
    Il 5\% della popolazione ha un'altezza inferiore a circa 166.8 cm.
\end{enumerate}
\end{esempio}

\newpage

\subsection*{Come usare la Tabella per Z Positivi}
\begin{itemize}
    \item La \textbf{colonna di sinistra} ti dà il valore di $z$ fino al primo decimale.
    \item La \textbf{riga in alto} ti dà il secondo decimale.
    \item Il valore all'incrocio tra riga e colonna è $\Phi(z)$.
\end{itemize}
\textbf{Esempio: Per trovare $\Phi(1.23)$:}
\begin{enumerate}
    \item Vai alla riga 1.2.
    \item Spostati a destra fino alla colonna 0.03.
    \item Il valore che trovi è 0.8907. Quindi $\Phi(1.23) = 0.8907$.
\end{enumerate}

\subsubsection*{Come trovare i valori per Z NEGATIVI?}
La tabella non li riporta perché non è necessario, grazie alla simmetria della curva a campana. Si usa la seguente regola:
\begin{formulabox}
    $\Phi(-z) = 1 - \Phi(z)$
\end{formulabox}
\textbf{Esempio: Per trovare $\Phi(-1.23)$:}
\begin{enumerate}
    \item Trova $\Phi(1.23)$ dalla tabella: $\Phi(1.23) = 0.8907$.
    \item Calcola $1 - 0.8907 = 0.1093$.
    \item Quindi $\Phi(-1.23) = 0.1093$.
\end{enumerate}
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{positiveztable.png}
\end{figure}
\newpage
\section{Statistiche Campionarie}
\begin{itemize}
    \item \textbf{Il contesto:} Immagina di voler conoscere l'altezza media di tutti gli italiani. È impossibile misurarli tutti. Cosa facciamo? Estraiamo un \textbf{campione} (es. 1000 persone) e misuriamo la loro altezza.

    \item \textbf{Modellizzazione (i.i.d.):} Modelliamo le osservazioni del nostro campione ($n$ dati) come $n$ variabili aleatorie $X_1, X_2, \dots, X_n$. Facciamo un'assunzione fondamentale: che queste v.a. siano \textbf{i.i.d.} (indipendenti e identicamente distribuite).
    \begin{itemize}
        \item \textbf{Indipendenti:} La scelta di una persona nel campione non influenza la scelta di un'altra.
        \item \textbf{Identicamente distribuite:} Tutte le $X_i$ seguono la stessa distribuzione di probabilità (quella della popolazione generale da cui stiamo campionando). Hanno tutte la stessa media $\mu$ e la stessa varianza $\sigma^2$ (che però non conosciamo).
    \end{itemize}
\end{itemize}

\begin{definizione}[Statistica Campionaria]
"Ogni combinazione di tali variabili è detta statistica campionaria." \\
\textbf{Spiegazione:} Una statistica campionaria è una funzione calcolata a partire dai dati del campione. È essa stessa una variabile aleatoria, perché se estraessimo un campione diverso, otterremmo un valore diverso.
\end{definizione}

\subsection{La Media Campionaria $\bar{X}$}
\begin{definizione}
È la statistica campionaria più importante, usata per stimare la vera media della popolazione $\mu$.
\begin{formulabox}
    $\bar{X} = \frac{X_1 + X_2 + \dots + X_n}{n} = \frac{1}{n} \sum_{i=1}^{n} X_i$
\end{formulabox}
\end{definizione}

\subsubsection*{Proprietà della Media Campionaria}
\begin{itemize}
    \item \textbf{Valore Atteso di $\bar{X}$: $E(\bar{X}) = \mu$} \\
    Il valore atteso della media campionaria è uguale alla vera media della popolazione. Questo significa che la media campionaria è uno \textbf{stimatore corretto} (o non distorto). In media, non sovrastima né sottostima la vera media.

    \item \textbf{Varianza di $\bar{X}$: $Var(\bar{X}) = \sigma^2/n$} \\
    Questa è una proprietà FONDAMENTALE: all'aumentare della dimensione del campione $n$, la varianza della media campionaria \textbf{diminuisce}. Le medie calcolate su campioni più grandi sono più "stabili", "precise" e meno disperse attorno alla vera media $\mu$.
\end{itemize}

\subsection{I Due Teoremi Fondamentali della Statistica}

\begin{regola}[Legge dei Grandi Numeri (LLN)]
\textbf{Traduzione in parole semplici:} Man mano che la dimensione del campione $n$ diventa infinitamente grande, la probabilità che la media campionaria $\bar{X}$ sia "vicina quanto si vuole" alla vera media $\mu$ tende a 1 (diventa una certezza). \\
\textbf{Significato pratico:} Se prendi un campione abbastanza grande, la media che calcoli sarà una stima molto, molto buona della vera media.
\end{regola}

\begin{regola}[Teorema del Limite Centrale (TLC)]
La LLN ci dice che la media campionaria converge a $\mu$. Il TLC ci dice \textbf{come} si distribuisce durante questa convergenza. \\
\textbf{Il risultato magico:} Qualunque sia la distribuzione di partenza delle $X_i$, se $n$ è abbastanza grande (di solito $n \ge 30$), la distribuzione della media campionaria $\bar{X}$ sarà \textbf{approssimativamente Normale}.
\begin{formulabox}
    $\bar{X} \approx N\left(\mu, \frac{\sigma^2}{n}\right)$
\end{formulabox}
\textbf{Perché è così potente?} Ci permette di usare la distribuzione Normale per fare calcoli e inferenza sulla media di una popolazione, anche se non sappiamo assolutamente nulla sulla forma della distribuzione di quella popolazione. Questa è la spina dorsale della statistica inferenziale.
\end{regola}

\newpage

\section{Approssimazione Normale della Binomiale}
\subsection{Il Problema: Calcoli Complessi con la Binomiale}
\begin{esempio}
Lanciamo una moneta 100 volte. Qual è la probabilità che il numero di teste X sia tra 40 e 70 (inclusi)?
\end{esempio}
\textbf{Identificazione del modello:} Il numero di successi (teste) in $n=100$ prove di Bernoulli indipendenti con $p=0.5$ è una v.a. Binomiale $X \sim B(100, 0.5)$. \\
\textbf{Il calcolo esatto:} Per trovare la risposta, dovremmo sommare le probabilità per ogni singolo valore:
\[ P(40 \le X \le 70) = \sum_{k=40}^{70} P(X=k) = \sum_{k=40}^{70} \binom{100}{k} (0.5)^k (0.5)^{100-k} \]
Sarebbe un incubo computazionale da fare a mano.

\subsection{La Soluzione: il Teorema del Limite Centrale}
Il TLC ci offre una via d'uscita elegante.
\begin{itemize}
    \item \textbf{L'idea:} Poiché la Binomiale X è una somma di $n$ v.a. i.i.d. (le singole Bernoulli), se $n$ è abbastanza grande, la sua distribuzione può essere approssimata da una Normale.

    \item \textbf{Verifica della condizione:} La regola pratica per una "buona" approssimazione è $np \ge 5$ e $n(1-p) \ge 5$.
    Nel nostro caso: $100 \cdot 0.5 = 50$, che è maggiore di 5. L'approssimazione sarà eccellente.

    \item \textbf{Identificazione della Normale approssimante:}
    La X Binomiale sarà approssimata da una Y Normale con la stessa media e varianza.
    \begin{itemize}
        \item Media: $\mu = np = 100 \cdot 0.5 = 50$.
        \item Varianza: $\sigma^2 = np(1-p) = 100 \cdot 0.5 \cdot 0.5 = 25$.
    \end{itemize}
    Quindi, $X \sim B(100, 0.5)$ viene approssimata da $Y \sim N(50, 25)$.
\end{itemize}

\subsection{Il Dettaglio Cruciale: La Correzione di Continuità}
\begin{itemize}
    \item \textbf{Il problema:} Stiamo approssimando una distribuzione a gradini (la Binomiale, che vive solo sugli interi 40, 41, 42...) con una curva liscia (la Normale, che vive su tutti i numeri reali).

    \item \textbf{Visualizzazione:} Immagina la distribuzione Binomiale come un istogramma, con barre centrate su 40, 41, etc. La barra per $X=40$ in realtà copre l'intervallo da 39.5 a 40.5. La barra per $X=70$ copre da 69.5 a 70.5.

    \item \textbf{La logica della correzione:} La probabilità $P(40 \le X \le 70)$ è la somma delle aree delle barre da 40 a 70. Per approssimare bene quest'area con la curva Normale, dobbiamo integrare sull'intervallo che copre \textbf{tutte le barre intere}, dal loro inizio alla loro fine.

    \item \textbf{La regola:} "si applica una correzione di continuità, cioè una modifica dell'intervallo di integrazione".
    \begin{formulabox}
        La richiesta discreta $P(40 \le X \le 70)$ diventa una richiesta continua $P(39.5 \le Y \le 70.5)$.
    \end{formulabox}
\end{itemize}

\subsubsection*{Calcoli Finali dell'Esempio}
Abbiamo trasformato il problema in $P(39.5 \le Y \le 70.5)$ dove $Y \sim N(50, 25)$.
\begin{enumerate}
    \item \textbf{Standardizzare l'intervallo ($\mu=50, \sigma=5$):}
    \begin{itemize}
        \item Estremo inferiore: $z_1 = (39.5 - 50) / 5 = -2.1$.
        \item Estremo superiore: $z_2 = (70.5 - 50) / 5 = 4.1$.
    \end{itemize}
    La nostra probabilità diventa $P(-2.1 \le Z \le 4.1)$.

    \item \textbf{Usare la $\Phi$:}
    \[ P(-2.1 \le Z \le 4.1) = \Phi(4.1) - \Phi(-2.1) \]
    Usando la simmetria $\Phi(-2.1) = 1 - \Phi(2.1)$:
    \[ \Phi(4.1) - (1 - \Phi(2.1)) = \Phi(4.1) + \Phi(2.1) - 1 \]

    \item \textbf{Cercare i valori sulle tavole e calcolare:}
    $\Phi(4.1) \approx 1$ e $\Phi(2.1) \approx 0.9821$.
    \[ P \approx 1 + 0.9821 - 1 = 0.9821 \]
\end{enumerate}
\textbf{Conclusione:} C'è circa il 98.2\% di probabilità di ottenere un numero di teste compreso tra 40 e 70.

\end{document}

